{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6700f463-7507-40b6-b412-187066596827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084dd5e9-c3d9-46ff-9c33-5fb1edce199a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/25 13:03:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('ReadSensonrData') \\\n",
    "    .config('spark.driver.memory', '5g') \\\n",
    "    .config('spark.executor.memory', '5g') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0d178-bbfd-429c-baec-5a0b9ec99a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# İndirdiğimiz verinin yolu\n",
    "base_path = \"sensor_data/KETI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf7afb-fafe-464b-8e4e-103baee985f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verideki tüm sensör tipleri (Odaların içindeki csv dosyaları)\n",
    "sensor_types = [\"co2\", \"humidity\", \"light\", \"pir\", \"temperature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8360a83-9587-4d1d-bcdd-56b7219d87c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Tüm sensor dflerini dfs değişkeninde alıyorum\n",
    "dfs = {}\n",
    "\n",
    "for sensor in sensor_types:\n",
    "    # Her bir sensör için dataframe oluşturuyorum.\n",
    "    sensor_path = f\"{base_path}/*/{sensor}.csv\"\n",
    "\n",
    "    df = spark.read.option(\"header\", False).csv(sensor_path) \\\n",
    "        .withColumn(\"file_path\", F.input_file_name()) \\\n",
    "        .withColumn(\"room_id\", F.regexp_extract(\"file_path\", rf\"/([^/]+)/{sensor}\\.csv\", 1)) \\\n",
    "        .withColumnRenamed(\"_c0\", \"sensor_unix_epoch_time\") \\\n",
    "        .withColumnRenamed(\"_c1\", \"sensor_value\") \\\n",
    "        .withColumn(\"sensor_timestamp\", F.from_unixtime(F.col(\"sensor_unix_epoch_time\").cast(\"bigint\"))) \\\n",
    "        .withColumn(\"sensor_datetime_hm\", F.date_format(\"sensor_timestamp\", \"yyyy-MM-dd HH:mm\")) # Aggregate de kullanmak için\n",
    "    dfs[sensor] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e23949-5e18-424b-a25d-727f0a1abc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sensor, df in dfs.items():\n",
    "    # Tip dönüşümleri\n",
    "    df = df.withColumn(\"sensor_unix_epoch_time\", F.col(\"sensor_unix_epoch_time\").cast(\"long\")) \\\n",
    "           .withColumn(\"sensor_value\", F.col(\"sensor_value\").cast(\"double\")) \\\n",
    "           .withColumn(\"sensor_timestamp\", F.col(\"sensor_timestamp\").cast(\"timestamp\"))\n",
    "    \n",
    "    dfs[sensor] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c6964-ffb7-41f0-b926-4feb920d9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Room id ve sensor_datetime_hm ye göre ortalama sensör değerlerini aldım\n",
    "agg_dfs = {} \n",
    "for sensor, df in dfs.items():\n",
    "    agg_df = df.groupBy(\"room_id\", \"sensor_datetime_hm\").agg(\n",
    "        F.round(F.avg(\"sensor_value\"), 3).alias(f\"avg_{sensor}\"),\n",
    "        F.min(\"sensor_timestamp\").alias(f\"{sensor}_sensor_timestamp\"))\n",
    "    agg_dfs[sensor] = agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c6c1f0-8736-4f62-8f90-dc5fe915bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_co2 = agg_dfs[\"co2\"]\n",
    "df_humidity = agg_dfs[\"humidity\"]\n",
    "df_light = agg_dfs[\"light\"]\n",
    "df_pir = agg_dfs[\"pir\"]\n",
    "df_temperature = agg_dfs[\"temperature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa491fb-b6e6-4d72-b38b-15e0a701adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En çok kayda sahip CO2 ye göre joinliyorum\n",
    "df_joined = df_co2 \\\n",
    "    .join(df_humidity, on=[\"sensor_datetime_hm\", \"room_id\"], how=\"left\") \\\n",
    "    .join(df_light, on=[\"sensor_datetime_hm\", \"room_id\"], how=\"left\") \\\n",
    "    .join(df_pir, on=[\"sensor_datetime_hm\", \"room_id\"], how=\"left\") \\\n",
    "    .join(df_temperature, on=[\"sensor_datetime_hm\", \"room_id\"], how=\"left\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede81cd-f46a-4ecb-9ee3-824057efb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diske yazılacak df in alanları\n",
    "final_df = df_joined.select(\n",
    "    \"sensor_datetime_hm\", \n",
    "    \"room_id\",\n",
    "    \"avg_co2\",\n",
    "    \"avg_humidity\",\n",
    "    \"avg_light\",\n",
    "    \"avg_pir\",\n",
    "    \"avg_temperature\"\n",
    ").orderBy(\"sensor_datetime_hm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8f6d366-17d4-40ac-8208-e341db9431f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f910a4e3-ba88-4e15-a34d-8c7941cfe556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+-------+------------+---------+-------+---------------+\n",
      "|sensor_datetime_hm|room_id|avg_co2|avg_humidity|avg_light|avg_pir|avg_temperature|\n",
      "+------------------+-------+-------+------------+---------+-------+---------------+\n",
      "|2013-08-23 23:04  |510    |404.0  |52.62       |204.0    |0.0    |23.46          |\n",
      "|2013-08-23 23:04  |621    |500.0  |49.115      |67.5     |14.0   |25.59          |\n",
      "|2013-08-23 23:04  |511    |389.0  |52.75       |250.5    |0.0    |22.62          |\n",
      "|2013-08-23 23:04  |746    |633.0  |52.84       |29.0     |21.0   |23.06          |\n",
      "|2013-08-23 23:04  |644    |468.5  |52.385      |165.0    |0.0    |22.805         |\n",
      "+------------------+-------+-------+------------+---------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.limit(5).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e717ac7f-692c-413a-b3ad-1f627560476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "103242fe-47be-403b-8d2a-1626c0df15d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_df.write.mode(\"overwrite\").parquet(os.path.join(output_dir, \"sensor_data.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30703810-715c-4a4d-9f28-5662e66e2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
